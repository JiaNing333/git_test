{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e0f416",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests as rqs\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re,json # re 是正規表達式\n",
    "\n",
    "my_headers = {\n",
    "    'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.71 Safari/537.36'\n",
    "}\n",
    "\n",
    "listData = []\n",
    "\n",
    "url = 'https://www.zeczec.com/'\n",
    "\n",
    "pages = 1 # 可以改 ,你想去哪一頁就去哪一頁\n",
    "\n",
    "def getMainData():\n",
    "    for page in range(1, pages + 1):\n",
    "        r = rqs.get(url = url + f\"categories?page={page}\", headers=my_headers)\n",
    "#         print(r.text)\n",
    "        soup = bs(r.text,\"lxml\")\n",
    "#         print(soup)\n",
    "        for a in soup.select('div.flex.gutter3-l a.db'): #取得所有圖片超連結\n",
    "#             print(a.select_one('div.aspect-ratio-project-cover')) 為了看到圖片的屬性 data-bg-src\n",
    "            strStyle = a.select_one('div.aspect-ratio-project-cover')['data-bg-src']  #有圖片屬性就可以取得圖片\n",
    "#             print(strStyle)\n",
    "            regexImg = r\"https:\\/\\/s3-ap-northeast-1\\.amazonaws\\.com\\/zeczec-prod\\/asset_\\d+_image_big\\.(jpe?g|png)\"  # 圖片網址的正規表達式\n",
    "            matchImg = re.match(regexImg,strStyle) # (圖片的正規表達式的變數名稱,要測試的字串)\n",
    "            strImg = matchImg[0] #結果放在這裡面\n",
    "#             print(strImg) # 取得其中圖片的資料\n",
    "            strLink = url+a['href'] #取得內文連結\n",
    "#             print(strLink) \n",
    "            strTitle = a.select_one('h3.b').get_text() # 取得每一個 Title\n",
    "#             print(strTitle)\n",
    "            listData.append({\n",
    "                \"cover\":strImg,\n",
    "                \"link\":strLink,\n",
    "                \"title\":strTitle\n",
    "            }) \n",
    "#     print(listData) # 取得每一筆 封面 , 連結 , 標題 用 list 裝起來\n",
    "def getDetailData():# 取得更詳細的網頁資訊 \n",
    "    for index,_dict in enumerate(listData): # 用列舉 index 0-11 , _dict會對應到上面的listData裡面的字典資訊\n",
    "        r = rqs.get(url = _dict['link'],headers = my_headers)\n",
    "#         print(r.text)\n",
    "        soup = bs(r.text,\"lxml\")\n",
    "        strPrice = soup.select_one('div.js-sum-raised').get_text()\n",
    "        regexPrice = r\"\\d+\"\n",
    "        strPrice = ''.join(re.findall(regexPrice, strPrice)) # ''.join 把 list 合併再一起,單純只輸出數字\n",
    "#         print(strPrice)\n",
    "        strBacker = soup.select_one('span.js-backers-count').get_text() # 取得贊助人數\n",
    "#         print(strBacker)\n",
    "        strTime = \"longterm\" \n",
    "        if soup.select_one('span.js-time-left') != None:\n",
    "            strTime = soup.select_one('span.js-time-left').get_text() #會印出43天\n",
    "            regexTime = r\"\\d+\"\n",
    "            strTime = re.search(regexTime,strTime)[0] # 沒有天\n",
    "#         print(strTime) # 印出剩餘天數\n",
    "        dictDuration = {'begin':'' , 'end':''}\n",
    "        strDuration = soup.select_one('div.mb2.f7').get_text()\n",
    "        regexDuration = r\"(\\d{4}\\/\\d{2}/\\d{2}\\s\\d{2}:\\d{2})(\\s–\\s(\\d{4}\\/\\d{2}\\/\\d{2}\\s\\d{2}:\\d{2}))?\"\n",
    "        matchDuration = re.search(regexDuration,strDuration)\n",
    "        dictDuration['begin'] = matchDuration[1] # 第一組數字依定會存在 begin 起始時間\n",
    "        if matchDuration[3] != None: \n",
    "            dictDuration['end'] = matchDuration[3]\n",
    "#         print(dictDuration)\n",
    "        listData[index]['price'] = strPrice\n",
    "        listData[index]['backer'] = strBacker\n",
    "        listData[index]['time'] = strTime\n",
    "        listData[index]['Duration'] = strDuration\n",
    "        listData[index]['comments'] = _dict['link'] + \"/comments\"\n",
    "        listData[index]['faqs'] = _dict['link'] + \"/faqs\"\n",
    "#     print(listData) 印出所有我取得的內容\n",
    "def saveJson(): # 變成 json 檔 , 比較好閱讀\n",
    "    with open(\"crowdfunding.json\",\"w\", encoding = \"utf-8\") as file:\n",
    "        file.write( json.dumps(listData, ensure_ascii=False, indent=4))\n",
    "if __name__ == \"__main__\":\n",
    "    getMainData()\n",
    "    getDetailData()\n",
    "    saveJson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c783073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
